{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from anytree import AnyNode\n",
    "from anytree.exporter import DotExporter\n",
    "from anytree.search import find\n",
    "from anytree import PreOrderIter\n",
    "from itertools import product\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print_mode = False\n",
    "\n",
    "def find_node(root, node_to_find):\n",
    "    \"\"\"\n",
    "    Traverse the tree to find the starting node by name.\n",
    "\n",
    "    Parameters:\n",
    "    root (Node): The root node of the tree\n",
    "    node_to_find (string): The name of the node to find\n",
    "\n",
    "    return:\n",
    "    Node: The starting node if found, otherwise None\n",
    "    \"\"\"\n",
    "    node = find(root, lambda node: node.name == node_to_find)\n",
    "    if print_mode:\n",
    "        if node:\n",
    "            print(f\"Node found: {node.name}\")\n",
    "        else:\n",
    "            print(\"Node not found\")\n",
    "\n",
    "    return node\n",
    "\n",
    "def generate_traces(node, calc_cost=False):\n",
    "    \"\"\"\n",
    "    Recursively generates all possible traces from the given node.\n",
    "\n",
    "    Parameters:\n",
    "    node (Node): The current node in the tree.\n",
    "    calc_cost (bool): Whether to calculate the cost of each trace.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of all possible traces from the given node.\n",
    "    list: A list of the cost of each trace.\n",
    "    \"\"\"\n",
    "    # If the node has no children, it is a leaf node (ACT), end of a trace\n",
    "    if not hasattr(node, 'children') or not node.children:\n",
    "        if calc_cost:\n",
    "            return [[node.name]], [node.costs]\n",
    "        else:\n",
    "            return [[node.name]], []\n",
    "\n",
    "    traces = []\n",
    "    costs = []\n",
    "\n",
    "    if node.type == \"OR\":\n",
    "        # OR node: Select one child at a time\n",
    "        for child in node.children:\n",
    "            child_traces, child_cost = generate_traces(child, calc_cost)\n",
    "            for trace in child_traces:\n",
    "                traces.append([node.name] + trace)\n",
    "            if calc_cost:\n",
    "                for cost in child_cost:\n",
    "                    costs.append(cost)\n",
    "\n",
    "    elif node.type == \"SEQ\" or node.type == \"AND\":\n",
    "        # SEQ/AND node: Concatenate traces of all children in order\n",
    "        child_traces = []\n",
    "        child_costs = []\n",
    "        for child in node.children:\n",
    "            # Recursively generate traces and costs for each child\n",
    "            child_traces_i, child_costs_i = generate_traces(child, calc_cost)\n",
    "            child_traces.append(child_traces_i)\n",
    "            child_costs.append(child_costs_i)\n",
    "\n",
    "        # Generate all combinations of traces from children\n",
    "        for combination in product(*child_traces):\n",
    "            traces.append([node.name] + [step for trace in combination for step in trace])\n",
    "\n",
    "        if calc_cost:\n",
    "            # Sum the costs for each combination of child traces\n",
    "            for combination in product(*child_costs):\n",
    "                costs.append(np.sum([cost for cost in combination], axis=0))\n",
    "\n",
    "    return traces, costs\n",
    "\n",
    "def build_tree(json_node, parent=None):\n",
    "    \"\"\"\n",
    "    Build the entire tree from the JSON object.\n",
    "\n",
    "    Parameters:\n",
    "    json_node (dict): The JSON object representing the tree\n",
    "    parent (Node): The parent node\n",
    "\n",
    "    Returns:\n",
    "    Node: The root node of the tree\n",
    "    \"\"\"\n",
    "    # Extract attributes from the JSON node, excluding 'name', 'type', and 'children'\n",
    "    attributes = {k: v for k, v in json_node.items() if k not in ['name', 'type', 'children']}\n",
    "    \n",
    "    # Create a new node with the extracted attributes\n",
    "    node = AnyNode(name=json_node['name'], type=json_node['type'], violation=False, parent=parent, **attributes)\n",
    "    \n",
    "    # Recursively build the tree for each child node\n",
    "    for child in json_node.get('children', []):\n",
    "        build_tree(child, node)\n",
    "    \n",
    "    return node\n",
    "\n",
    "def annotate_tree(node, norm):\n",
    "    \"\"\"\n",
    "    Annotates the tree by marking nodes that violate the given norm.\n",
    "\n",
    "    Parameters:\n",
    "    node (Node): The current node in the tree\n",
    "    norm (dict): The norm\n",
    "\n",
    "    - If the norm is of type 'P' (prohibited), a node violates it if its name is in norm['actions'].\n",
    "    - If the norm is of type 'O' (obligatory), a node violates it if it is an action but not in norm['actions'].\n",
    "    \"\"\"\n",
    "    # Recursively annotate each child node\n",
    "    for child in node.children:\n",
    "        annotate_tree(child, norm)\n",
    "\n",
    "    # Check if the current node violates the norm\n",
    "    if 'type' in norm:\n",
    "        if norm['type'] == 'P':\n",
    "            # Prohibited norm: node violates if its name is in norm['actions']\n",
    "            node.violation = node.name in norm['actions']\n",
    "        elif norm['type'] == 'O':\n",
    "            # Obligatory norm: node violates if it is an action but not in norm['actions']\n",
    "            node.violation = node.name not in norm['actions'] and node.type == 'ACT'\n",
    "\n",
    "    # For OR nodes, the node violates if all children violate\n",
    "    if hasattr(node, 'type') and node.type == 'OR':\n",
    "        node.violation = all(child.violation for child in node.children)\n",
    "    # For SEQ/AND nodes, the node violates if any child violates\n",
    "    elif hasattr(node, 'type') and node.type in ['SEQ', 'AND']:\n",
    "        node.violation = any(child.violation for child in node.children)\n",
    "\n",
    "def export_tree_to_png(root, output_file):\n",
    "    \"\"\"\n",
    "    Exports the tree to a PNG file with node properties.\n",
    "\n",
    "    Parameters:\n",
    "    root (Node): The root node of the tree\n",
    "    output_file (string): The path to the output file\n",
    "    \"\"\"\n",
    "    DotExporter(root, \n",
    "                nodeattrfunc=lambda node: f'label=\"{node.name}\\nViolation: {node.violation}\"'\n",
    "               ).to_picture(output_file)\n",
    "\n",
    "def make_decision(json_tree, norm, goal, beliefs, preferences, output_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Main function to determine the best execution trace for the agent.\n",
    "\n",
    "    Parameters:\n",
    "    json_tree (json object): The goal tree \n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    output_dir (string): The directory to save the output image\n",
    "\n",
    "    Returns:\n",
    "    tree (Node): The root node of the tree\n",
    "    chosen_trace (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    valid_traces (list): A list of all valid traces\n",
    "    valid_costs (list): A list of the cost of each valid trace\n",
    "    \"\"\"\n",
    "    # Build the tree from the JSON object\n",
    "    root = build_tree(json_tree)\n",
    "\n",
    "    # Annotate the tree based on the given norm\n",
    "    annotate_tree(root, norm)\n",
    "\n",
    "    # Generate all possible traces of the given tree, and calculate the cost of each trace\n",
    "    traces, costs = generate_traces(root, calc_cost=True)\n",
    "\n",
    "    if print_mode:\n",
    "        print(\"costs: \", costs)\n",
    "        print(f\"Generated {len(traces)} traces:\")\n",
    "        for trace in traces:\n",
    "            print(trace)\n",
    "\n",
    "    # Filter traces that violate norms and keep their respective costs\n",
    "    valid_traces = []\n",
    "    valid_costs = []\n",
    "    \n",
    "    for trace, cost in zip(traces, costs):\n",
    "        valid = True\n",
    "        has_all_goals = [False for goal_belief in goal]\n",
    "        agent_beliefs = beliefs.copy()\n",
    "\n",
    "        for node_name in trace:\n",
    "            node = find(root, lambda node: node.name == node_name)\n",
    "\n",
    "            # Check if node found\n",
    "            if not node:\n",
    "                continue\n",
    "\n",
    "            # Check if the node violates any norms\n",
    "            if node.violation:\n",
    "                valid = False\n",
    "                if print_mode:\n",
    "                    print(f\"Trace violates norm: {trace}\")\n",
    "                break  \n",
    "\n",
    "            # Check if the node violates any preconditions\n",
    "            if (node and hasattr(node, 'pre') and any(pre not in agent_beliefs for pre in node.pre)):\n",
    "                valid = False\n",
    "                if print_mode:\n",
    "                    print(f\"Trace violates beliefs: {trace}\")\n",
    "                    print(f\"Current Agent Beliefs: {agent_beliefs}\")\n",
    "                    print(f\"Node pre: {node.pre}\")\n",
    "                break\n",
    "\n",
    "            # Update agent beliefs given the execution of the current node\n",
    "            if node and hasattr(node, 'post'):\n",
    "                agent_beliefs.extend(node.post)\n",
    "\n",
    "                # Check if all goals are achieved\n",
    "                for i, goal_belief in enumerate(goal):\n",
    "                    if hasattr(node, 'post') and goal_belief in node.post:\n",
    "                        has_all_goals[i] = True\n",
    "\n",
    "        # If the trace is valid and all goals are achieved, add it to the valid traces\n",
    "        if valid and all(has_all_goals):            \n",
    "            valid_traces.append(trace)\n",
    "            valid_costs.append(cost)\n",
    "\n",
    "    # Sort traces based on user preferences\n",
    "    if preferences and len(preferences) == 2:\n",
    "        indices = preferences[1]\n",
    "        sorted_traces_and_costs = sorted(zip(valid_traces, valid_costs), key=lambda x: tuple(x[1][i] for i in indices))\n",
    "        valid_traces, valid_costs = zip(*sorted_traces_and_costs) if sorted_traces_and_costs else ([], [])\n",
    "\n",
    "    # Return the best trace\n",
    "    chosen_trace = valid_traces[0] if valid_traces else []\n",
    "    if print_mode:\n",
    "        print(f\"Best trace: {chosen_trace}\")\n",
    "    \n",
    "    return root, chosen_trace, valid_traces, valid_costs\n",
    "\n",
    "\n",
    "def create_explanation(key=\"\", node_name=None, value=[]):\n",
    "    \"\"\"\n",
    "    Creates an explanation for a given key, node name, and value.\n",
    "\n",
    "    Parameters:\n",
    "    key (string): The key of the explanation\n",
    "    node_name (string): The name of the node\n",
    "    value (list): The value of the explanation\n",
    "\n",
    "    Returns:\n",
    "    list: A list representing the explanation\n",
    "    \"\"\"\n",
    "\n",
    "    if node_name is None:\n",
    "        return [key] + value\n",
    "    \n",
    "    return [key, node_name] + value\n",
    "\n",
    "\n",
    "def add_explanation(explanations, key=\"\", node_name=None, value=[]):\n",
    "    \"\"\"\n",
    "    Adds an explanation to the list of explanations.\n",
    "\n",
    "    Parameters:\n",
    "    explanations (list): The list of explanations\n",
    "    key (string): The key of the explanation\n",
    "    node_name (string): The name of the node\n",
    "    value (list): The value of the explanation\n",
    "    \"\"\"\n",
    "    explanations.append(create_explanation(key, node_name, value))\n",
    "\n",
    "def get_cost_of_node(traces, costs, node):\n",
    "    \"\"\"\n",
    "    Calculate the cost of a given node.\n",
    "\n",
    "    Parameters:\n",
    "    traces (list): A list of all possible traces\n",
    "    costs (list): A list of the cost of each trace\n",
    "    node (Node): The node for which to calculate the cost\n",
    "\n",
    "    Returns:\n",
    "    list: The cost of the node\n",
    "    \"\"\"\n",
    "    if not traces or not costs or not node:\n",
    "        return []\n",
    "    \n",
    "    if hasattr(node, 'costs'):\n",
    "        return node.costs\n",
    "\n",
    "    # Find the index of the node in the traces\n",
    "    node_index = next((i for i, trace in enumerate(traces) if node.name in trace), None)\n",
    "\n",
    "    # If the node is not found in the traces, return an empty list\n",
    "    if node_index is None:\n",
    "        return []\n",
    "    \n",
    "    # Return the cost of the node\n",
    "    return costs[node_index]\n",
    "\n",
    "def add_linked_node_explanations(explanations, node, root):\n",
    "     if hasattr(node, 'link') and node.link:\n",
    "        for dest_node_name in node.link:\n",
    "            linked_node = find_node(root, dest_node_name)\n",
    "            if linked_node:\n",
    "                add_explanation(explanations, key='L', node_name=node.name, value=['->', dest_node_name])\n",
    "            if hasattr(linked_node, 'link') and node.link:\n",
    "                add_linked_node_explanations(explanations, linked_node, root)\n",
    "\n",
    "\n",
    "\n",
    "def generate_formal_explanations(json_tree, norm, goal, beliefs, preferences, action_to_explain, output_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Explain why a certain action was executed as part of a selected execution trace\n",
    "\n",
    "    Parameters:\n",
    "    json_tree (json object): The goal tree \n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    action_to_explain (string): The name of the action to explain.\n",
    "    output_dir (string): The directory to save the output image\n",
    "\n",
    "    Returns:\n",
    "    output (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    chosen_trace (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    \"\"\"\n",
    "\n",
    "    explanations = []\n",
    "\n",
    "    # Use part 3 code to get selected trace - Get the root node, the chosen trace, and the valid traces\n",
    "    root, chosen_trace, valid_traces, valid_costs = make_decision(json_tree, norm, goal, beliefs, preferences, output_dir)\n",
    "\n",
    "\n",
    "    print(f\"Chosen trace: {chosen_trace}\")\n",
    "    if not chosen_trace or len(chosen_trace) == 0 or action_to_explain not in chosen_trace:\n",
    "        print(f\"Action to explain: {action_to_explain} not in trace\")\n",
    "        # If the action is not in the trace, return an empty list\n",
    "        return [], chosen_trace\n",
    "    else:\n",
    "        print(f\"Action to explain: {action_to_explain} in trace\")\n",
    "\n",
    "\n",
    "    # Get target node to explain\n",
    "    target_node = find_node(root, action_to_explain)\n",
    "    if not target_node:\n",
    "        return [], chosen_trace\n",
    "\n",
    "    if hasattr(target_node, 'ancestors'):\n",
    "        ancestor_names = [ancestor.name for ancestor in target_node.ancestors]\n",
    "        print(f\"Ancestor names: {ancestor_names}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Starting generating the explanation, according to the pdf it should contain a list of explanatory factors as defined below.\n",
    "    The list should be obtained by traversing the tree in pre-order.\n",
    "    \"\"\"    \n",
    "    agent_beliefs = beliefs.copy()\n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        current_node_type = None\n",
    "        if hasattr(node, 'type'):\n",
    "            current_node_type = node.type\n",
    "\n",
    "        if current_node_name in chosen_trace:\n",
    "            \"\"\" \n",
    "            (a) Pre-conditions of an action (denoted with a “P\"). Requested format:\n",
    "                ['P', action name,\n",
    "                list of preconditions of the actions (including A) that were satisfied and that\n",
    "                made the execution of action A that is being explained possible]\n",
    "                Example: ['P', 'getOwnCard', ['ownCard']]\n",
    "                Note: No \"P\" factor should be included in the list if an action has no preconditions.\n",
    "            \"\"\"\n",
    "            if hasattr(node, 'pre') and node.name in chosen_trace and hasattr(node, 'type') and node.type in ['ACT']:\n",
    "                # Add preconditions of cuurent action to the global preconditions list\n",
    "                add_explanation(explanations, key='P', node_name=node.name, value=[node.pre.copy()])\n",
    "            \n",
    "            # Update agent beliefs given the execution of the current node\n",
    "            if hasattr(node, 'post'):\n",
    "                agent_beliefs.extend(node.post)\n",
    "\n",
    "            # Handle OR nodes (b, c, d, e explanations [C, V, N, F])\n",
    "            if current_node_type == 'OR':\n",
    "                chosen_child = next(child for child in node.children if child.name in chosen_trace)\n",
    "                chosen_child_name = chosen_child.name\n",
    "                for child in node.children:\n",
    "                    child_name = child.name\n",
    "                    if child_name in chosen_trace:\n",
    "                        \"\"\"\n",
    "                        (b) A condition of a choice (“C\"). Requested format:\n",
    "                            ['C', name of alternative that was chosen for an OR node,\n",
    "                            list of preconditions of the alternative that were satisfied and that\n",
    "                            made the choice possible]\n",
    "                            Example: ['C', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "                            Note: getKitchenCoffee is one of the alternatives of the getCoffee OR node\n",
    "                        \"\"\"\n",
    "                        add_explanation(explanations, key='C', node_name=child_name, value=[chosen_child.pre.copy()])\n",
    "                    else:\n",
    "                        \"\"\"\n",
    "                        An explanation for each alternative not selected, either via a ”N” factor, a\n",
    "                        ”V” factor, or a ”F” factor explanation, depending on the reason. Note:\n",
    "                        if, for one alternative not selected, multiple reasons are true, only report\n",
    "                        the first factor, considering the order above (i.e., a ”V” factor only if no\n",
    "                        ”N” factor is relevant, and a ”F” factor only if no ”N” nor ”V” factors are\n",
    "                        releant).\n",
    "                        \"\"\"\n",
    "\n",
    "                        \"\"\"\n",
    "                        (d) A norm (\"N\"). Requested format:\n",
    "                            ['N', name of an alternative of an OR node that was NOT chosen because\n",
    "                            it violates (possibly through its children) a norm,\n",
    "                            the norm that is violated]\n",
    "                            Example: ['N', 'getShopCoffee', 'P(payShop)']\n",
    "                        \"\"\"\n",
    "                        if hasattr(child, \"violation\") and child.violation:\n",
    "                            norm_string = f\"{norm['type']}({', '.join(norm['actions'])})\"\n",
    "                            add_explanation(explanations, key='N', node_name=child.name, value=[norm_string])\n",
    "                            continue\n",
    "                        \"\"\"\n",
    "                        (c) A value statement (“V\"). Requested format:\n",
    "                            ['V', name of an alternative that was chosen for an OR node,\n",
    "                            list of costs for that alternative,\n",
    "                            '>',\n",
    "                            name of another alternative of an OR node that was NOT chosen,\n",
    "                            list of costs for that alternative]\n",
    "                            Example:\n",
    "                            ['V', 'getKitchenCoffee', [5.0, 0.0, 3.0],\n",
    "                            '>',\n",
    "                            'getAnnOfficeCoffee', [2.0, 0.0, 6.0]]\n",
    "                        \"\"\"   \n",
    "                        unsatisfied_preconditions = []\n",
    "                        if hasattr(child, 'pre'):\n",
    "                            unsatisfied_preconditions = [pre for pre in child.pre if pre not in agent_beliefs]             \n",
    "\n",
    "                        if len(unsatisfied_preconditions) == 0:\n",
    "                            chosen_child_cost = get_cost_of_node(valid_traces, valid_costs, chosen_child)                            \n",
    "                            child_cost = get_cost_of_node(valid_traces, valid_costs, child)\n",
    "                            child_cost_formatted = child_cost.tolist() if isinstance(child_cost, np.ndarray) else child_cost\n",
    "                            chosen_child_cost_formatted = chosen_child_cost.tolist() if isinstance(chosen_child_cost, np.ndarray) else chosen_child_cost\n",
    "                            add_explanation(explanations, key='V', \n",
    "                                            node_name=chosen_child_name, \n",
    "                                            value=[chosen_child_cost_formatted, '>',child_name, child_cost_formatted])\n",
    "                            continue\n",
    "                        \n",
    "\n",
    "                        \"\"\"\n",
    "                        (e) A failed condition of a choice (\"F\"). Requested format:\n",
    "                            ['F', name of an alternative of an OR node that was NOT chosen because\n",
    "                            (some of) its pre-conditions were not satisfied,\n",
    "                            list of preconditions of the alternative that were NOT\n",
    "                            satisfied and made the choice not possible]\n",
    "                            Example: ['F', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "                        \"\"\"                        \n",
    "                        add_explanation(explanations, key='F', node_name=child_name, value=[unsatisfied_preconditions])\n",
    "                        continue\n",
    "            \n",
    "            \"\"\" (g) A goal (\"D\"). Requested format:\n",
    "                ['D', name of the goal]\n",
    "                Example: ['D', 'getKitchenCoffee']\n",
    "            \"\"\"\n",
    "            if current_node_type in ['SEQ', 'AND', 'OR'] and ancestor_names and len(ancestor_names) > 0 and current_node_name in ancestor_names:\n",
    "                add_explanation(explanations, key='D', value=[current_node_name])\n",
    "\n",
    "        # Check if the current node is the action to explain\n",
    "        if current_node_name == action_to_explain:\n",
    "            \"\"\"\n",
    "            (f) A link (“L\"). Requested format:\n",
    "                ['L', name of the node, '->', name of the linked node]\n",
    "                Example: ['L', 'payShop', '->', 'getCoffeeShop']\n",
    "                Note: a node a links to another node b if a's attribute \"link\" contains the\n",
    "                name of b. Furthermore, if the linked node b also has a link to another node c,\n",
    "                then the explanation should also include such a link (and all the links forming\n",
    "                a chain starting from a) to the explanation, i.e., for each link in the chain an\n",
    "                explanation in the requested format above should included in the list.\n",
    "            \"\"\"\n",
    "            add_linked_node_explanations(explanations, node, root)\n",
    "            # Stop the traversal if the action to explain is reached\n",
    "            break\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\" (h) The user preference (\"U\"). Requested format:\n",
    "        ['U' the pair given in input as user preference]\n",
    "        Example: ['U', [['quality', 'price', 'time'], [1, 2, 0]]]\n",
    "    \"\"\"\n",
    "    if preferences and len(preferences) == 2:\n",
    "        add_explanation(explanations, key='U', value=[preferences])\n",
    "\n",
    "\n",
    "    return explanations, chosen_trace\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "\"\"\"\n",
    "\n",
    "def handle_condition_explanation(action, formal_explention):\n",
    "    conditions = ', '.join(formal_explention[2])\n",
    "    return f\"The agent was able to perform the action '{action}' as all its preconditions ({conditions}) were successfully met.\"\n",
    "\n",
    "def handle_value_comparison_explanation(action1, values1, operator, action2, values2, preferences_labels, preferences_values, preference_labels_formatted):\n",
    "    value1_formatted = ', '.join([f\"{label}: {value}\" for label, value in zip(preferences_labels, values1)])\n",
    "    value2_formatted = ', '.join([f\"{label}: {value}\" for label, value in zip(preferences_labels, values2)])\n",
    "    \n",
    "    if values1 == values2:\n",
    "        return f\"Both actions have the same values for all factors ({value1_formatted}), so the agent randomly chose '{action1}' over '{action2}.\"\n",
    "    \n",
    "    explanation = f\"The agent chose '{action1}' over '{action2}' based on the user's preferences to prioritize {preference_labels_formatted}\"\n",
    "\n",
    "    # Compare the values succinctly\n",
    "    explanation += f\" and given that '{action1}' has these values: \" + value1_formatted\n",
    "    explanation += f\", while '{action2}' has: \" + value2_formatted\n",
    "\n",
    "    # Find the decisive factor\n",
    "    for index in preferences_values:\n",
    "        preference_label = preferences_labels[index]\n",
    "        value1 = values1[index]\n",
    "        value2 = values2[index]\n",
    "\n",
    "        if value1 != value2:\n",
    "            explanation += f\". The decisive factor was the {preference_label}, as '{action2}' had a higher value of {value2} compared to '{action1}' with {value1}. Lower values are more desirable, so '{action1}' was chosen.\"\n",
    "            break\n",
    "\n",
    "    # If all values are equal\n",
    "    if not any(value1 != value2 for value1, value2 in zip(values1, values2)):\n",
    "        explanation += f\". Since all factors were equally matched, the agent randomly chose the first action ({action1}).\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def handle_norm_violation_explanation(action, formal_explention):\n",
    "    norm = formal_explention[2]\n",
    "    norm_type = norm[0]\n",
    "    norm_action = norm[2:-1]\n",
    "    \n",
    "    if norm_type == \"P\":  # Prohibition Norm\n",
    "        if norm_action == action:\n",
    "            return f\"The action '{action}' is not allowed because it violates the prohibition norm, which states that this action cannot be executed.\"\n",
    "        \n",
    "        return f\"The action '{action}' is not allowed because it leads to the execution of a prohibited action. The prohibition norm specifies that the following action must not be performed: {norm_action}.\"\n",
    "    \n",
    "    elif norm_type == \"O\":  # Obligation Norm\n",
    "        return f\"The action '{action}' is not allowed because it violates the obligation norm, which specifies that only the following action(s) are permitted: {norm_action}.\"\n",
    "\n",
    "def handle_precondition_explanation(action, formal_explention):\n",
    "    preconditions = formal_explention[2]\n",
    "    if len(preconditions) > 1:\n",
    "        preconditions_formatted = ', '.join(preconditions[:-1]) + ', and ' + preconditions[-1]\n",
    "        return f\"The agent could not perform '{action}' because the obligatory preconditions: {preconditions_formatted} were not met.\"\n",
    "    else:\n",
    "        preconditions_formatted = preconditions[0]\n",
    "        return f\"The agent could not perform '{action}' because the obligatory precondition: {preconditions_formatted} was not met.\"\n",
    "\n",
    "def handle_decision_explanation(action):\n",
    "    return f\"The agent chose to perform '{action}' as it is a necessary step to achieve the goal action.\"\n",
    "\n",
    "def handle_link_explanation(action, formal_explention):\n",
    "    linked_action = formal_explention[3]\n",
    "    return f\"The action '{action}' is linked to the action '{linked_action}', and as such, it was executed as a necessary step to achieve the goal action.\"\n",
    "\n",
    "def handle_utility_function_explanation(preferences):\n",
    "    preferences_labels = preferences[0]\n",
    "    preferences_values = preferences[1]\n",
    "    # Sort preferences_labels according to preferences_values\n",
    "    preference_labels_sorted = [preferences_labels[i] for i in preferences_values]\n",
    "    preference_labels_formatted = format_list_to_string(preference_labels_sorted)\n",
    "    return f\"The agent's preferences, in descending order of importance, are: {preference_labels_formatted}.\"\n",
    "\n",
    "def handle_failure_explanation(action, formal_explention):\n",
    "    \"\"\"\n",
    "    (e) A failed condition of a choice (\"F\"). Requested format:\n",
    "        ['F', name of an alternative of an OR node that was NOT chosen because\n",
    "        (some of) its pre-conditions were not satisfied,\n",
    "        list of preconditions of the alternative that were NOT\n",
    "        satisfied and made the choice not possible]\n",
    "        Example: ['F', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "    \"\"\"     \n",
    "    # action = formal_explention[1]\n",
    "    preconditions = formal_explention[2]\n",
    "    preconditions_labels_formatted = format_list_to_string(preconditions)\n",
    "    \n",
    "    return f\"The agent cound not executed '{action}' because of the preconditions for it, which are {preconditions_labels_formatted}, were not met.\"\n",
    "\n",
    "def generate_natural_explentions(formal_explention, preferences):\n",
    "    \"\"\"\n",
    "    Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "    :param formal_explention: a single formal explentions (output of part1-4)\n",
    "    :param preferences: user preferences\n",
    "    :return: natural language explention\n",
    "    \"\"\"\n",
    "    explanation_type = formal_explention[0]\n",
    "    action = formal_explention[1]\n",
    "    preferences_labels = preferences[0]\n",
    "    preferences_values = preferences[1]\n",
    "    # Sort preferences_labels according to preferences_values\n",
    "    preference_labels_sorted = [preferences_labels[i] for i in preferences_values]\n",
    "    preference_labels_formatted = format_list_to_string(preference_labels_sorted)\n",
    "\n",
    "    if explanation_type == 'C':  # Condition\n",
    "        return handle_condition_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'V':  # Value Comparison\n",
    "        action1, values1, operator, action2, values2 = formal_explention[1:]\n",
    "        return handle_value_comparison_explanation(action1, values1, operator, action2, values2, preferences_labels, preferences_values, preference_labels_formatted)\n",
    "    elif explanation_type == 'N':  # Norm Violation\n",
    "        return handle_norm_violation_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'P':  # Precondition\n",
    "        return handle_precondition_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'D':  # Decision\n",
    "        return handle_decision_explanation(action)\n",
    "    elif explanation_type == 'L':  # Link\n",
    "        return handle_link_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'U':  # Utility Function\n",
    "        return handle_utility_function_explanation(preferences)\n",
    "    elif explanation_type == 'F':\n",
    "        return handle_failure_explanation(action, formal_explention)\n",
    "    \n",
    "    return \"Unknown explanation type.\"\n",
    "\n",
    "def format_list_to_string(lst):\n",
    "    \"\"\"\n",
    "    Format a list of strings into a single string with commas and 'and' before the last element.\n",
    "    :param lst: The list of strings to format.\n",
    "    :return: The formatted string.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(lst) > 1:\n",
    "        return ', '.join(lst[:-1]) + ', and ' + lst[-1]\n",
    "    return lst[0]\n",
    "\n",
    "def generate_restriction_description(norm, goal, beliefs, preferences, action_to_explain):\n",
    "    \"\"\"\n",
    "    Generate a natural language description of the restrictions placed on the agent.\n",
    "    \n",
    "    Parameters:\n",
    "    norm (dict): The norm restricting or obligating actions.\n",
    "    goal (list): The desired outcome, represented as a set of beliefs that must be true by the end of execution.\n",
    "    beliefs (list): The agent's initial knowledge.\n",
    "    preferences (list): A pair describing the end-user's priority order.\n",
    "    action_to_explain (string): The action being analyzed.\n",
    "    \n",
    "    :return: A natural language description of the restrictions.\n",
    "    \"\"\"\n",
    "\n",
    "    restrictions = []\n",
    "\n",
    "    # Describe norm\n",
    "    if norm:\n",
    "        norm_type = norm.get(\"type\", \"Unknown\")\n",
    "        norm_actions = norm.get(\"actions\", [])\n",
    "\n",
    "        if norm_actions:\n",
    "            norm_action_str = format_list_to_string(norm_actions)\n",
    "            if norm_type == \"P\":\n",
    "                restrictions.append(f\"Restricted actions: {norm_action_str}.\")\n",
    "            elif norm_type == \"O\":\n",
    "                restrictions.append(f\"Required actions: {norm_action_str}.\")\n",
    "\n",
    "    # Describe initial beliefs\n",
    "    if beliefs:\n",
    "        restrictions.append(f\"Starting beliefs: {format_list_to_string(beliefs)}.\")\n",
    "\n",
    "    # Describe goal\n",
    "    if goal:\n",
    "        restrictions.append(f\"Goal: {format_list_to_string(goal)}.\")\n",
    "\n",
    "    # Describe preferences\n",
    "    preferences_description = handle_utility_function_explanation(preferences)\n",
    "    restrictions.append(preferences_description)\n",
    "\n",
    "    # Combine everything into a natural flow\n",
    "    restriction_sentence = \" \".join(restrictions)\n",
    "    return f\"To explain the action '{action_to_explain}', consider the following context: {restriction_sentence}\"\n",
    "\n",
    "\n",
    "def generate_naive_baseline(formal_explentions, chosen_trace, norm, goal, beliefs, preferences, action_to_explain):\n",
    "    \"\"\"\n",
    "    Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "    \n",
    "    Parameters:\n",
    "    formal_explentions (list): list of formal explentions (output of part1-4)\n",
    "    chosen_trace (list): chosen trace\n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    action_to_explain (string): The name of the action to explain.\n",
    "\n",
    "    :return: list of natural language explentions\n",
    "    \"\"\"\n",
    "    natural_explentions = []\n",
    "    # Format the chosen trace for display\n",
    "    chosen_trace_formatted = \"\"\n",
    "    if chosen_trace is not None and len(chosen_trace) > 0:\n",
    "       chosen_trace_formatted = format_list_to_string(chosen_trace)\n",
    "\n",
    "    restriction_description = generate_restriction_description(norm, goal, beliefs, preferences, action_to_explain)\n",
    "    natural_explentions.append(restriction_description)\n",
    "\n",
    "    if formal_explentions is None or len(formal_explentions) == 0:\n",
    "        if chosen_trace:\n",
    "            natural_explentions.append(\n",
    "                f\"The action '{action_to_explain}' was not executed in the chosen trace ({chosen_trace_formatted}).\"\n",
    "            )\n",
    "\n",
    "        if norm and norm.get(\"type\") == \"P\" and action_to_explain in norm.get(\"actions\", []):\n",
    "            natural_explentions.append(\"This action is restricted by the norm and therefore could not be executed.\")\n",
    "\n",
    "        return natural_explentions\n",
    "\n",
    "    # Generate natural language explanations for each formal explanation\n",
    "    for explention in formal_explentions:\n",
    "        natural_explentions.append(generate_natural_explentions(explention, preferences))\n",
    "\n",
    "    return natural_explentions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed pipeline a bit, added preorder_traversal list to follow the order in which the agent decides what to do;\n",
    "### function generate_comprehensive_explanation generates response from mistral https://ollama.com/library/mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Code: 404\n",
      "Response Content: 404 page not found\n",
      "JSONDecodeError: Extra data: line 1 column 5 (char 4)\n",
      "Status Code: 404\n",
      "Response Content: 404 page not found\n",
      "JSONDecodeError: Extra data: line 1 column 5 (char 4)\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoints\n",
    "api_base = \"http://localhost:11434/api/v1\"\n",
    "embedding_api_base = \"http://localhost:11434/api/v1\"\n",
    "\n",
    "# Example request to the LLM model\n",
    "llm_payload = {\n",
    "    \"input\": \"Translate formal explanation to natural language: C: getKitchenCoffee requires [staffCardAvailable]\"\n",
    "}\n",
    "response = requests.post(f\"{api_base}/generate\", json=llm_payload)\n",
    "\n",
    "# Debugging: Print response status code and content\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response Content: {response.text}\")\n",
    "\n",
    "try:\n",
    "    print(response.json())\n",
    "except requests.exceptions.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "\n",
    "# Example request to the embedding model\n",
    "embedding_payload = {\n",
    "    \"input\": \"This is a sample text to embed.\"\n",
    "}\n",
    "response = requests.post(f\"{embedding_api_base}/embed\", json=embedding_payload)\n",
    "\n",
    "# Debugging: Print response status code and content\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response Content: {response.text}\")\n",
    "\n",
    "try:\n",
    "    print(response.json())\n",
    "except requests.exceptions.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "from anytree import PreOrderIter\n",
    "\n",
    "def preorder_traversal(root):\n",
    "    \"\"\"\n",
    "    Performs a preorder traversal of a tree and returns a list of node names.\n",
    "    \n",
    "    :param root: The root node of the tree.\n",
    "    :return: A list of node names in preorder traversal order.\n",
    "    \"\"\"\n",
    "    preorder_traversal_nodes = []\n",
    "    \n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        print(current_node_name)\n",
    "        preorder_traversal_nodes.append(current_node_name)\n",
    "    \n",
    "    return preorder_traversal_nodes\n",
    "\n",
    "def generate_natural_language_explanation(naive_explanation, formal_explanations, tree_traversal_order, \n",
    "                                     norm, beliefs, goal, preferences, action_to_explain, chosen_trace=None):\n",
    "    \n",
    "    # Format key context elements in plain English\n",
    "    norm_str = norm if norm else \"None\"\n",
    "    beliefs_str = \", \".join(beliefs) if beliefs else \"None\"\n",
    "    goal_str = goal if goal else \"None\"\n",
    "    pref_description = f\"{preferences[0]} with costs {preferences[1]}\"\n",
    "    chosen_trace_str = \", \".join(chosen_trace) if chosen_trace else \"None\"\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    You are an AI agent explaining your decision-making process to a human user.\n",
    "    \n",
    "    Generate a natural, conversational explanation about why you performed a specific action while achieving a goal.\n",
    "    Do no use technical terms or jargon. Explain your reasoning in a way that a non-expert can understand.\n",
    "    Do not be overly verbose. Keep the explanation concise and to the point.\n",
    "    Do not generate exentric or creative explanations. Stick to the facts and reasoning.\n",
    "    Include at the begining all information of restrictions, beliefs, goals, preferences, and actions, then the selected trace and only then start explining the reasoning.\n",
    "    If agent faild with explaning the action or there was no selected trace state that at the begining.\n",
    "    \n",
    "    CONTEXT:\n",
    "    - Action I need to explain: {action_to_explain}\n",
    "    - Norm/restriction I know: {norm_str}\n",
    "    - My initial beliefs: {beliefs_str}\n",
    "    - Goal I was given: {goal_str}\n",
    "    - User's preferences: {pref_description}\n",
    "    - Actions I performed: {chosen_trace_str}\n",
    "    \n",
    "    HOW I EXPLORED OPTIONS (reasoning tree traversal):\n",
    "    {tree_traversal_order}\n",
    "    \n",
    "    TECHNICAL EXPLANATION (needs conversion to natural language):\n",
    "    {naive_explanation}\n",
    "    \n",
    "    DETAILED REASONING CODES:\n",
    "    {formal_explanations}\n",
    "    \n",
    "    YOUR TASK:\n",
    "    Create a natural, conversational explanation that:\n",
    "    1. Follows the exact reasoning path I took when making decisions\n",
    "    2. Starts by acknowledging the user's goal and preferences\n",
    "    3. Explains each decision point in order, showing:\n",
    "       - How I started with the main goal\n",
    "       - How I considered different options\n",
    "       - Why I chose certain actions and rejected others\n",
    "       - How preconditions, norms, and preferences affected my choices\n",
    "    4. Translates each reasoning code into natural language:\n",
    "       - P codes → explain what conditions made an action possible\n",
    "       - C codes → explain what allowed me to make a choice\n",
    "       - F codes → explain why some options weren't possible\n",
    "       - N codes → explain which norms prevented certain actions\n",
    "       - V codes → explain why I preferred one option over another\n",
    "       - L codes → explain how actions are connected or dependent\n",
    "       - D codes → explain how actions helped achieve the goal\n",
    "       - U codes → explain how user preferences guided my decisions\n",
    "    \n",
    "    IMPORTANT:\n",
    "    - Write in first person (\"I\") as if I'm the agent speaking directly to the user\n",
    "    - Use simple, conversational language (no technical terms)\n",
    "    - Create a flowing narrative that shows how one decision led to the next\n",
    "    - Specifically explain why I performed {action_to_explain}\n",
    "    - Keep the explanation concise but complete\n",
    "    - Write as a flowing paragraph, not a list or bullet points\n",
    "\n",
    "\n",
    "    Deeper context on how the formal explanations were generated:\n",
    "    (a) Pre-conditions of an action (denoted with a “P\"). Requested format:\n",
    "                ['P', action name,\n",
    "                list of preconditions of the actions (including A) that were satisfied and that\n",
    "                made the execution of action A that is being explained possible]\n",
    "                Example: ['P', 'getOwnCard', ['ownCard']]\n",
    "                Note: No \"P\" factor should be included in the list if an action has no preconditions.\n",
    "    \n",
    "    (b) A condition of a choice (“C\"). Requested format:\n",
    "                            ['C', name of alternative that was chosen for an OR node,\n",
    "                            list of preconditions of the alternative that were satisfied and that\n",
    "                            made the choice possible]\n",
    "                            Example: ['C', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "                            Note: getKitchenCoffee is one of the alternatives of the getCoffee OR node\n",
    "    \n",
    "    (c) A value statement (“V\"). Requested format:\n",
    "                            ['V', name of an alternative that was chosen for an OR node,\n",
    "                            list of costs for that alternative,\n",
    "                            '>',\n",
    "                            name of another alternative of an OR node that was NOT chosen,\n",
    "                            list of costs for that alternative]\n",
    "                            Example:\n",
    "                            ['V', 'getKitchenCoffee', [5.0, 0.0, 3.0],\n",
    "                            '>',\n",
    "                            'getAnnOfficeCoffee', [2.0, 0.0, 6.0]]\n",
    "    \n",
    "    (d) A norm (\"N\"). Requested format:\n",
    "                            ['N', name of an alternative of an OR node that was NOT chosen because\n",
    "                            it violates (possibly through its children) a norm,\n",
    "                            the norm that is violated]\n",
    "                            Example: ['N', 'getShopCoffee', 'P(payShop)']\n",
    "    \n",
    "    (e) A failed condition of a choice (\"F\"). Requested format:\n",
    "                            ['F', name of an alternative of an OR node that was NOT chosen because\n",
    "                            (some of) its pre-conditions were not satisfied,\n",
    "                            list of preconditions of the alternative that were NOT\n",
    "                            satisfied and made the choice not possible]\n",
    "                            Example: ['F', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "    \n",
    "    \n",
    "    (f) A link (“L\"). Requested format:\n",
    "                ['L', name of the node, '->', name of the linked node]\n",
    "                Example: ['L', 'payShop', '->', 'getCoffeeShop']\n",
    "                Note: a node a links to another node b if a's attribute \"link\" contains the\n",
    "                name of b. Furthermore, if the linked node b also has a link to another node c,\n",
    "                then the explanation should also include such a link (and all the links forming\n",
    "                a chain starting from a) to the explanation, i.e., for each link in the chain an\n",
    "                explanation in the requested format above should included in the list.\n",
    "    \n",
    "    (g) A goal (\"D\"). Requested format:\n",
    "                ['D', name of the goal]\n",
    "                Example: ['D', 'getKitchenCoffee']\n",
    "    \n",
    "    (h) The user preference (\"U\"). Requested format:\n",
    "        ['U' the pair given in input as user preference]\n",
    "        Example: ['U', [['quality', 'price', 'time'], [1, 2, 0]]]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send the prompt to your LLM\n",
    "    api_base = \"http://localhost:11434\"\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    # response = requests.post(f\"{api_base}/chat\", json={\"model\": \"mistral\", \"messages\": messages})\n",
    "    response = ollama.chat(model='mistral', messages=messages)\n",
    "    \n",
    "    try:\n",
    "        return response['message']['content']\n",
    "    except requests.exceptions.JSONDecodeError as e:\n",
    "        print(f\"JSONDecodeError: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def preorder_traversal(root):\n",
    "    \"\"\"\n",
    "    Performs a preorder traversal of a tree and returns a list of node names.\n",
    "    \n",
    "    :param root: The root node of the tree.\n",
    "    :return: A list of node names in preorder traversal order.\n",
    "    \"\"\"\n",
    "    preorder_traversal_nodes = []\n",
    "    \n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        print(current_node_name)\n",
    "        preorder_traversal_nodes.append(current_node_name)\n",
    "    \n",
    "    return preorder_traversal_nodes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated here llm explanations and save them into explanations/mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanations_for_inputs(test_cases):\n",
    "    \"\"\"\n",
    "    Generate explanations for the inputs test cases\n",
    "    :param test_cases: dictionary containing the test cases\n",
    "    :return: dictionary containing the explanations for each test case\n",
    "    \"\"\"\n",
    "    \n",
    "    # in .ipynb current directory is extracted like this\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # current_dir = os.path.dirname(__file__)\n",
    "\n",
    "    baseline_explanations_dir = os.path.join(current_dir, \"explanations\", \"baseline\")\n",
    "    os.makedirs(baseline_explanations_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    llm_explanations_dir = os.path.join(current_dir, \"explanations\", \"mistral\")\n",
    "    \n",
    "    baseline_explanations = {}\n",
    "    llm_explanations = {}\n",
    "    for index, row in test_cases.iterrows():\n",
    "        # Read the JSON file into a dictionary\n",
    "        with open(f'{current_dir}/{row[\"name_json_tree_file\"]}', 'r') as file:\n",
    "            json_tree = json.load(file)\n",
    "        # Generate formal explanations\n",
    "        formal_explentions, chosen_trace = generate_formal_explanations(json_tree=json_tree, norm=row[\"norm\"], beliefs=row[\"beliefs\"], goal=row[\"goal\"], preferences=row[\"preferences\"], action_to_explain=row[\"action_to_explain\"])\n",
    "        baseline_explanations[index] = generate_naive_baseline(formal_explentions=formal_explentions, chosen_trace=chosen_trace, norm=row[\"norm\"], beliefs=row[\"beliefs\"], goal=row[\"goal\"], preferences=row[\"preferences\"], action_to_explain=row[\"action_to_explain\"])\n",
    "\n",
    "\n",
    "\n",
    "        root, chosen_trace, valid_traces, valid_costs = make_decision(json_tree, norm=row[\"norm\"], goal=row[\"goal\"], beliefs=row[\"beliefs\"], preferences=row[\"preferences\"], output_dir='/')\n",
    "        tree_traversal_order = preorder_traversal(root=root)\n",
    "\n",
    "        # print(f\"naive_explanation {baseline_explanations[index]}, formal_explanations {formal_explentions}, norm {row['norm']}, beliefs {row['beliefs']}, preferences {row['preferences']}\")\n",
    "\n",
    "\n",
    "        llm_explanations[index] = generate_natural_language_explanation(\n",
    "                        naive_explanation=baseline_explanations[index],\n",
    "                        formal_explanations=formal_explentions,\n",
    "                        tree_traversal_order=tree_traversal_order,\n",
    "                        norm=row[\"norm\"],\n",
    "                        beliefs=row[\"beliefs\"],\n",
    "                        goal=row[\"goal\"],\n",
    "                        preferences=row[\"preferences\"],\n",
    "                        action_to_explain=row[\"action_to_explain\"],\n",
    "                        chosen_trace=chosen_trace\n",
    "                        )\n",
    "\n",
    "        # Save each explanation to a separate text file\n",
    "        baseline_explanation_file = os.path.join(baseline_explanations_dir, f\"{index}.txt\")\n",
    "        with open(baseline_explanation_file, 'w') as f:\n",
    "            for explanation in baseline_explanations[index]:\n",
    "                f.write(explanation + '\\n')\n",
    "\n",
    "\n",
    "        os.makedirs(llm_explanations_dir, exist_ok=True)  \n",
    "\n",
    "        llm_explanation_file = os.path.join(llm_explanations_dir, f\"{index}.txt\")\n",
    "\n",
    "        print(f\"directory ---> {llm_explanation_file}\")\n",
    "        \n",
    "        # with open(llm_explanation_file, 'w') as f:\n",
    "        #     for explanation in llm_explanations[index]:\n",
    "        #         f.write(explanation + '\\n')\n",
    "\n",
    "        # Loop through the dictionary and write explanations for each test case\n",
    "        with open(llm_explanation_file, 'w') as f:\n",
    "            for explanation in llm_explanations[index]:\n",
    "                # Write the explanation for this test case\n",
    "                f.write(explanation)   # Add an extra newline for separation\n",
    "\n",
    "        \n",
    "    \n",
    "    return baseline_explanations, llm_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"payShop\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [1, 2, 0]],\n",
    "        \"action_to_explain\": \"payShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"getCoffeeKitchen\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {},\n",
    "        \"beliefs\": [\"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"getCoffeeShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"gotoAnnOffice\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"payShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"payShop\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [1, 2, 0]],\n",
    "        \"action_to_explain\": \"gotoKitchen\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df_test_cases = pd.DataFrame(test_cases, index=[f\"test_case_{i+1}\" for i in range(len(test_cases))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen trace: ['getCoffee', 'getKitchenCoffee', 'getStaffCard', 'getOwnCard', 'gotoKitchen', 'getCoffeeKitchen']\n",
      "Action to explain: payShop not in trace\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n",
      "directory ---> c:\\Users\\bar24\\OneDrive - Universiteit Utrecht\\Documents\\School\\UU Data Sceince MSc\\1st Year\\Period 3\\Explainable AI - INFOMXAI\\Assignments\\Project2\\ExplainableAI-Project2\\Part2\\explanations\\mistral\\test_case_1.txt\n",
      "Chosen trace: ['getCoffee', 'getKitchenCoffee', 'getStaffCard', 'getOwnCard', 'gotoKitchen', 'getCoffeeKitchen']\n",
      "Action to explain: getCoffeeKitchen in trace\n",
      "Ancestor names: ['getCoffee', 'getKitchenCoffee']\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n",
      "directory ---> c:\\Users\\bar24\\OneDrive - Universiteit Utrecht\\Documents\\School\\UU Data Sceince MSc\\1st Year\\Period 3\\Explainable AI - INFOMXAI\\Assignments\\Project2\\ExplainableAI-Project2\\Part2\\explanations\\mistral\\test_case_2.txt\n",
      "Chosen trace: ['getCoffee', 'getShopCoffee', 'gotoShop', 'payShop', 'getCoffeeShop']\n",
      "Action to explain: getCoffeeShop in trace\n",
      "Ancestor names: ['getCoffee', 'getShopCoffee']\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n",
      "directory ---> c:\\Users\\bar24\\OneDrive - Universiteit Utrecht\\Documents\\School\\UU Data Sceince MSc\\1st Year\\Period 3\\Explainable AI - INFOMXAI\\Assignments\\Project2\\ExplainableAI-Project2\\Part2\\explanations\\mistral\\test_case_3.txt\n",
      "Chosen trace: ['getCoffee', 'getShopCoffee', 'gotoShop', 'payShop', 'getCoffeeShop']\n",
      "Action to explain: payShop in trace\n",
      "Ancestor names: ['getCoffee', 'getShopCoffee']\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n",
      "directory ---> c:\\Users\\bar24\\OneDrive - Universiteit Utrecht\\Documents\\School\\UU Data Sceince MSc\\1st Year\\Period 3\\Explainable AI - INFOMXAI\\Assignments\\Project2\\ExplainableAI-Project2\\Part2\\explanations\\mistral\\test_case_4.txt\n",
      "Chosen trace: ['getCoffee', 'getKitchenCoffee', 'getStaffCard', 'getOwnCard', 'gotoKitchen', 'getCoffeeKitchen']\n",
      "Action to explain: gotoKitchen in trace\n",
      "Ancestor names: ['getCoffee', 'getKitchenCoffee']\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n",
      "directory ---> c:\\Users\\bar24\\OneDrive - Universiteit Utrecht\\Documents\\School\\UU Data Sceince MSc\\1st Year\\Period 3\\Explainable AI - INFOMXAI\\Assignments\\Project2\\ExplainableAI-Project2\\Part2\\explanations\\mistral\\test_case_5.txt\n"
     ]
    }
   ],
   "source": [
    "baseline_explanations, llm_explanations = generate_explanations_for_inputs(df_test_cases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "# Define the API endpoints\n",
    "api_base = \"http://localhost:11434\"\n",
    "\n",
    "# Example request to the LLM model\n",
    "llm_payload = {\n",
    "    \"input\": \"Translate formal explanation to natural language: C: getKitchenCoffee requires [staffCardAvailable]\"\n",
    "}\n",
    "response = requests.post(f\"{api_base}\", json=llm_payload)\n",
    "\n",
    "# Debugging: Print response status code and content\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response Content: {response.text}\")\n",
    "\n",
    "try:\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "except requests.exceptions.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")\n",
    "\n",
    "# Example request to the embedding model\n",
    "embedding_payload = {\n",
    "    \"input\": \"This is a sample text to embed.\"\n",
    "}\n",
    "response = requests.post(f\"{api_base}/embed\", json=embedding_payload)\n",
    "\n",
    "# Debugging: Print response status code and content\n",
    "print(f\"Status Code: {response.status_code}\")\n",
    "print(f\"Response Content: {response.text}\")\n",
    "\n",
    "try:\n",
    "    response_json = response.json()\n",
    "    print(response_json)\n",
    "except requests.exceptions.JSONDecodeError as e:\n",
    "    print(f\"JSONDecodeError: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ExplainableAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
