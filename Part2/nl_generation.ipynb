{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from anytree import AnyNode\n",
    "from anytree.exporter import DotExporter\n",
    "from anytree.search import find\n",
    "from anytree import PreOrderIter\n",
    "from itertools import product\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "print_mode = False\n",
    "\n",
    "def find_node(root, node_to_find):\n",
    "    \"\"\"\n",
    "    Traverse the tree to find the starting node by name.\n",
    "\n",
    "    Parameters:\n",
    "    root (Node): The root node of the tree\n",
    "    node_to_find (string): The name of the node to find\n",
    "\n",
    "    return:\n",
    "    Node: The starting node if found, otherwise None\n",
    "    \"\"\"\n",
    "    node = find(root, lambda node: node.name == node_to_find)\n",
    "    if print_mode:\n",
    "        if node:\n",
    "            print(f\"Node found: {node.name}\")\n",
    "        else:\n",
    "            print(\"Node not found\")\n",
    "\n",
    "    return node\n",
    "\n",
    "def generate_traces(node, calc_cost=False):\n",
    "    \"\"\"\n",
    "    Recursively generates all possible traces from the given node.\n",
    "\n",
    "    Parameters:\n",
    "    node (Node): The current node in the tree.\n",
    "    calc_cost (bool): Whether to calculate the cost of each trace.\n",
    "\n",
    "    Returns:\n",
    "    list: A list of all possible traces from the given node.\n",
    "    list: A list of the cost of each trace.\n",
    "    \"\"\"\n",
    "    # If the node has no children, it is a leaf node (ACT), end of a trace\n",
    "    if not hasattr(node, 'children') or not node.children:\n",
    "        if calc_cost:\n",
    "            return [[node.name]], [node.costs]\n",
    "        else:\n",
    "            return [[node.name]], []\n",
    "\n",
    "    traces = []\n",
    "    costs = []\n",
    "\n",
    "    if node.type == \"OR\":\n",
    "        # OR node: Select one child at a time\n",
    "        for child in node.children:\n",
    "            child_traces, child_cost = generate_traces(child, calc_cost)\n",
    "            for trace in child_traces:\n",
    "                traces.append([node.name] + trace)\n",
    "            if calc_cost:\n",
    "                for cost in child_cost:\n",
    "                    costs.append(cost)\n",
    "\n",
    "    elif node.type == \"SEQ\" or node.type == \"AND\":\n",
    "        # SEQ/AND node: Concatenate traces of all children in order\n",
    "        child_traces = []\n",
    "        child_costs = []\n",
    "        for child in node.children:\n",
    "            # Recursively generate traces and costs for each child\n",
    "            child_traces_i, child_costs_i = generate_traces(child, calc_cost)\n",
    "            child_traces.append(child_traces_i)\n",
    "            child_costs.append(child_costs_i)\n",
    "\n",
    "        # Generate all combinations of traces from children\n",
    "        for combination in product(*child_traces):\n",
    "            traces.append([node.name] + [step for trace in combination for step in trace])\n",
    "\n",
    "        if calc_cost:\n",
    "            # Sum the costs for each combination of child traces\n",
    "            for combination in product(*child_costs):\n",
    "                costs.append(np.sum([cost for cost in combination], axis=0))\n",
    "\n",
    "    return traces, costs\n",
    "\n",
    "def build_tree(json_node, parent=None):\n",
    "    \"\"\"\n",
    "    Build the entire tree from the JSON object.\n",
    "\n",
    "    Parameters:\n",
    "    json_node (dict): The JSON object representing the tree\n",
    "    parent (Node): The parent node\n",
    "\n",
    "    Returns:\n",
    "    Node: The root node of the tree\n",
    "    \"\"\"\n",
    "    # Extract attributes from the JSON node, excluding 'name', 'type', and 'children'\n",
    "    attributes = {k: v for k, v in json_node.items() if k not in ['name', 'type', 'children']}\n",
    "    \n",
    "    # Create a new node with the extracted attributes\n",
    "    node = AnyNode(name=json_node['name'], type=json_node['type'], violation=False, parent=parent, **attributes)\n",
    "    \n",
    "    # Recursively build the tree for each child node\n",
    "    for child in json_node.get('children', []):\n",
    "        build_tree(child, node)\n",
    "    \n",
    "    return node\n",
    "\n",
    "def annotate_tree(node, norm):\n",
    "    \"\"\"\n",
    "    Annotates the tree by marking nodes that violate the given norm.\n",
    "\n",
    "    Parameters:\n",
    "    node (Node): The current node in the tree\n",
    "    norm (dict): The norm\n",
    "\n",
    "    - If the norm is of type 'P' (prohibited), a node violates it if its name is in norm['actions'].\n",
    "    - If the norm is of type 'O' (obligatory), a node violates it if it is an action but not in norm['actions'].\n",
    "    \"\"\"\n",
    "    # Recursively annotate each child node\n",
    "    for child in node.children:\n",
    "        annotate_tree(child, norm)\n",
    "\n",
    "    # Check if the current node violates the norm\n",
    "    if 'type' in norm:\n",
    "        if norm['type'] == 'P':\n",
    "            # Prohibited norm: node violates if its name is in norm['actions']\n",
    "            node.violation = node.name in norm['actions']\n",
    "        elif norm['type'] == 'O':\n",
    "            # Obligatory norm: node violates if it is an action but not in norm['actions']\n",
    "            node.violation = node.name not in norm['actions'] and node.type == 'ACT'\n",
    "\n",
    "    # For OR nodes, the node violates if all children violate\n",
    "    if hasattr(node, 'type') and node.type == 'OR':\n",
    "        node.violation = all(child.violation for child in node.children)\n",
    "    # For SEQ/AND nodes, the node violates if any child violates\n",
    "    elif hasattr(node, 'type') and node.type in ['SEQ', 'AND']:\n",
    "        node.violation = any(child.violation for child in node.children)\n",
    "\n",
    "def export_tree_to_png(root, output_file):\n",
    "    \"\"\"\n",
    "    Exports the tree to a PNG file with node properties.\n",
    "\n",
    "    Parameters:\n",
    "    root (Node): The root node of the tree\n",
    "    output_file (string): The path to the output file\n",
    "    \"\"\"\n",
    "    DotExporter(root, \n",
    "                nodeattrfunc=lambda node: f'label=\"{node.name}\\nViolation: {node.violation}\"'\n",
    "               ).to_picture(output_file)\n",
    "\n",
    "def make_decision(json_tree, norm, goal, beliefs, preferences, output_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Main function to determine the best execution trace for the agent.\n",
    "\n",
    "    Parameters:\n",
    "    json_tree (json object): The goal tree \n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    output_dir (string): The directory to save the output image\n",
    "\n",
    "    Returns:\n",
    "    tree (Node): The root node of the tree\n",
    "    chosen_trace (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    valid_traces (list): A list of all valid traces\n",
    "    valid_costs (list): A list of the cost of each valid trace\n",
    "    \"\"\"\n",
    "    # Build the tree from the JSON object\n",
    "    root = build_tree(json_tree)\n",
    "\n",
    "    # Annotate the tree based on the given norm\n",
    "    annotate_tree(root, norm)\n",
    "\n",
    "    # Generate all possible traces of the given tree, and calculate the cost of each trace\n",
    "    traces, costs = generate_traces(root, calc_cost=True)\n",
    "\n",
    "    if print_mode:\n",
    "        print(\"costs: \", costs)\n",
    "        print(f\"Generated {len(traces)} traces:\")\n",
    "        for trace in traces:\n",
    "            print(trace)\n",
    "\n",
    "    # Filter traces that violate norms and keep their respective costs\n",
    "    valid_traces = []\n",
    "    valid_costs = []\n",
    "    \n",
    "    for trace, cost in zip(traces, costs):\n",
    "        valid = True\n",
    "        has_all_goals = [False for goal_belief in goal]\n",
    "        agent_beliefs = beliefs.copy()\n",
    "\n",
    "        for node_name in trace:\n",
    "            node = find(root, lambda node: node.name == node_name)\n",
    "\n",
    "            # Check if node found\n",
    "            if not node:\n",
    "                continue\n",
    "\n",
    "            # Check if the node violates any norms\n",
    "            if node.violation:\n",
    "                valid = False\n",
    "                if print_mode:\n",
    "                    print(f\"Trace violates norm: {trace}\")\n",
    "                break  \n",
    "\n",
    "            # Check if the node violates any preconditions\n",
    "            if (node and hasattr(node, 'pre') and any(pre not in agent_beliefs for pre in node.pre)):\n",
    "                valid = False\n",
    "                if print_mode:\n",
    "                    print(f\"Trace violates beliefs: {trace}\")\n",
    "                    print(f\"Current Agent Beliefs: {agent_beliefs}\")\n",
    "                    print(f\"Node pre: {node.pre}\")\n",
    "                break\n",
    "\n",
    "            # Update agent beliefs given the execution of the current node\n",
    "            if node and hasattr(node, 'post'):\n",
    "                agent_beliefs.extend(node.post)\n",
    "\n",
    "                # Check if all goals are achieved\n",
    "                for i, goal_belief in enumerate(goal):\n",
    "                    if hasattr(node, 'post') and goal_belief in node.post:\n",
    "                        has_all_goals[i] = True\n",
    "\n",
    "        # If the trace is valid and all goals are achieved, add it to the valid traces\n",
    "        if valid and all(has_all_goals):            \n",
    "            valid_traces.append(trace)\n",
    "            valid_costs.append(cost)\n",
    "\n",
    "    # Sort traces based on user preferences\n",
    "    if preferences and len(preferences) == 2:\n",
    "        indices = preferences[1]\n",
    "        sorted_traces_and_costs = sorted(zip(valid_traces, valid_costs), key=lambda x: tuple(x[1][i] for i in indices))\n",
    "        valid_traces, valid_costs = zip(*sorted_traces_and_costs) if sorted_traces_and_costs else ([], [])\n",
    "\n",
    "    # Return the best trace\n",
    "    chosen_trace = valid_traces[0] if valid_traces else []\n",
    "    if print_mode:\n",
    "        print(f\"Best trace: {chosen_trace}\")\n",
    "    \n",
    "    return root, chosen_trace, valid_traces, valid_costs\n",
    "\n",
    "\n",
    "def create_explanation(key=\"\", node_name=None, value=[]):\n",
    "    \"\"\"\n",
    "    Creates an explanation for a given key, node name, and value.\n",
    "\n",
    "    Parameters:\n",
    "    key (string): The key of the explanation\n",
    "    node_name (string): The name of the node\n",
    "    value (list): The value of the explanation\n",
    "\n",
    "    Returns:\n",
    "    list: A list representing the explanation\n",
    "    \"\"\"\n",
    "\n",
    "    if node_name is None:\n",
    "        return [key] + value\n",
    "    \n",
    "    return [key, node_name] + value\n",
    "\n",
    "\n",
    "def add_explanation(explanations, key=\"\", node_name=None, value=[]):\n",
    "    \"\"\"\n",
    "    Adds an explanation to the list of explanations.\n",
    "\n",
    "    Parameters:\n",
    "    explanations (list): The list of explanations\n",
    "    key (string): The key of the explanation\n",
    "    node_name (string): The name of the node\n",
    "    value (list): The value of the explanation\n",
    "    \"\"\"\n",
    "    explanations.append(create_explanation(key, node_name, value))\n",
    "\n",
    "def get_cost_of_node(traces, costs, node):\n",
    "    \"\"\"\n",
    "    Calculate the cost of a given node.\n",
    "\n",
    "    Parameters:\n",
    "    traces (list): A list of all possible traces\n",
    "    costs (list): A list of the cost of each trace\n",
    "    node (Node): The node for which to calculate the cost\n",
    "\n",
    "    Returns:\n",
    "    list: The cost of the node\n",
    "    \"\"\"\n",
    "    if not traces or not costs or not node:\n",
    "        return []\n",
    "    \n",
    "    if hasattr(node, 'costs'):\n",
    "        return node.costs\n",
    "\n",
    "    # Find the index of the node in the traces\n",
    "    node_index = next((i for i, trace in enumerate(traces) if node.name in trace), None)\n",
    "\n",
    "    # If the node is not found in the traces, return an empty list\n",
    "    if node_index is None:\n",
    "        return []\n",
    "    \n",
    "    # Return the cost of the node\n",
    "    return costs[node_index]\n",
    "\n",
    "def add_linked_node_explanations(explanations, node, root):\n",
    "     if hasattr(node, 'link') and node.link:\n",
    "        for dest_node_name in node.link:\n",
    "            linked_node = find_node(root, dest_node_name)\n",
    "            if linked_node:\n",
    "                add_explanation(explanations, key='L', node_name=node.name, value=['->', dest_node_name])\n",
    "            if hasattr(linked_node, 'link') and node.link:\n",
    "                add_linked_node_explanations(explanations, linked_node, root)\n",
    "\n",
    "\n",
    "\n",
    "def generate_formal_explanations(json_tree, norm, goal, beliefs, preferences, action_to_explain, output_dir=\"\"):\n",
    "    \"\"\"\n",
    "    Explain why a certain action was executed as part of a selected execution trace\n",
    "\n",
    "    Parameters:\n",
    "    json_tree (json object): The goal tree \n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    action_to_explain (string): The name of the action to explain.\n",
    "    output_dir (string): The directory to save the output image\n",
    "\n",
    "    Returns:\n",
    "    output (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    chosen_trace (list): A list of strings representing the execution trace chosen by the agent.\n",
    "    \"\"\"\n",
    "\n",
    "    explanations = []\n",
    "\n",
    "    # Use part 3 code to get selected trace - Get the root node, the chosen trace, and the valid traces\n",
    "    root, chosen_trace, valid_traces, valid_costs = make_decision(json_tree, norm, goal, beliefs, preferences, output_dir)\n",
    "\n",
    "\n",
    "    print(f\"Chosen trace: {chosen_trace}\")\n",
    "    if not chosen_trace or len(chosen_trace) == 0 or action_to_explain not in chosen_trace:\n",
    "        print(f\"Action to explain: {action_to_explain} not in trace\")\n",
    "        # If the action is not in the trace, return an empty list\n",
    "        return [], chosen_trace\n",
    "    else:\n",
    "        print(f\"Action to explain: {action_to_explain} in trace\")\n",
    "\n",
    "\n",
    "    # Get target node to explain\n",
    "    target_node = find_node(root, action_to_explain)\n",
    "    if not target_node:\n",
    "        return [], chosen_trace\n",
    "\n",
    "    if hasattr(target_node, 'ancestors'):\n",
    "        ancestor_names = [ancestor.name for ancestor in target_node.ancestors]\n",
    "        print(f\"Ancestor names: {ancestor_names}\")\n",
    "\n",
    "    \"\"\"\n",
    "    Starting generating the explanation, according to the pdf it should contain a list of explanatory factors as defined below.\n",
    "    The list should be obtained by traversing the tree in pre-order.\n",
    "    \"\"\"    \n",
    "    agent_beliefs = beliefs.copy()\n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        current_node_type = None\n",
    "        if hasattr(node, 'type'):\n",
    "            current_node_type = node.type\n",
    "\n",
    "        if current_node_name in chosen_trace:\n",
    "            \"\"\" \n",
    "            (a) Pre-conditions of an action (denoted with a “P\"). Requested format:\n",
    "                ['P', action name,\n",
    "                list of preconditions of the actions (including A) that were satisfied and that\n",
    "                made the execution of action A that is being explained possible]\n",
    "                Example: ['P', 'getOwnCard', ['ownCard']]\n",
    "                Note: No \"P\" factor should be included in the list if an action has no preconditions.\n",
    "            \"\"\"\n",
    "            if hasattr(node, 'pre') and node.name in chosen_trace and hasattr(node, 'type') and node.type in ['ACT']:\n",
    "                # Add preconditions of cuurent action to the global preconditions list\n",
    "                add_explanation(explanations, key='P', node_name=node.name, value=[node.pre.copy()])\n",
    "            \n",
    "            # Update agent beliefs given the execution of the current node\n",
    "            if hasattr(node, 'post'):\n",
    "                agent_beliefs.extend(node.post)\n",
    "\n",
    "            # Handle OR nodes (b, c, d, e explanations [C, V, N, F])\n",
    "            if current_node_type == 'OR':\n",
    "                chosen_child = next(child for child in node.children if child.name in chosen_trace)\n",
    "                chosen_child_name = chosen_child.name\n",
    "                for child in node.children:\n",
    "                    child_name = child.name\n",
    "                    if child_name in chosen_trace:\n",
    "                        \"\"\"\n",
    "                        (b) A condition of a choice (“C\"). Requested format:\n",
    "                            ['C', name of alternative that was chosen for an OR node,\n",
    "                            list of preconditions of the alternative that were satisfied and that\n",
    "                            made the choice possible]\n",
    "                            Example: ['C', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "                            Note: getKitchenCoffee is one of the alternatives of the getCoffee OR node\n",
    "                        \"\"\"\n",
    "                        add_explanation(explanations, key='C', node_name=child_name, value=[chosen_child.pre.copy()])\n",
    "                    else:\n",
    "                        \"\"\"\n",
    "                        An explanation for each alternative not selected, either via a ”N” factor, a\n",
    "                        ”V” factor, or a ”F” factor explanation, depending on the reason. Note:\n",
    "                        if, for one alternative not selected, multiple reasons are true, only report\n",
    "                        the first factor, considering the order above (i.e., a ”V” factor only if no\n",
    "                        ”N” factor is relevant, and a ”F” factor only if no ”N” nor ”V” factors are\n",
    "                        releant).\n",
    "                        \"\"\"\n",
    "\n",
    "                        \"\"\"\n",
    "                        (d) A norm (\"N\"). Requested format:\n",
    "                            ['N', name of an alternative of an OR node that was NOT chosen because\n",
    "                            it violates (possibly through its children) a norm,\n",
    "                            the norm that is violated]\n",
    "                            Example: ['N', 'getShopCoffee', 'P(payShop)']\n",
    "                        \"\"\"\n",
    "                        if hasattr(child, \"violation\") and child.violation:\n",
    "                            norm_string = f\"{norm['type']}({', '.join(norm['actions'])})\"\n",
    "                            add_explanation(explanations, key='N', node_name=child.name, value=[norm_string])\n",
    "                            continue\n",
    "                        \"\"\"\n",
    "                        (c) A value statement (“V\"). Requested format:\n",
    "                            ['V', name of an alternative that was chosen for an OR node,\n",
    "                            list of costs for that alternative,\n",
    "                            '>',\n",
    "                            name of another alternative of an OR node that was NOT chosen,\n",
    "                            list of costs for that alternative]\n",
    "                            Example:\n",
    "                            ['V', 'getKitchenCoffee', [5.0, 0.0, 3.0],\n",
    "                            '>',\n",
    "                            'getAnnOfficeCoffee', [2.0, 0.0, 6.0]]\n",
    "                        \"\"\"   \n",
    "                        unsatisfied_preconditions = []\n",
    "                        if hasattr(child, 'pre'):\n",
    "                            unsatisfied_preconditions = [pre for pre in child.pre if pre not in agent_beliefs]             \n",
    "\n",
    "                        if len(unsatisfied_preconditions) == 0:\n",
    "                            chosen_child_cost = get_cost_of_node(valid_traces, valid_costs, chosen_child)                            \n",
    "                            child_cost = get_cost_of_node(valid_traces, valid_costs, child)\n",
    "                            child_cost_formatted = child_cost.tolist() if isinstance(child_cost, np.ndarray) else child_cost\n",
    "                            chosen_child_cost_formatted = chosen_child_cost.tolist() if isinstance(chosen_child_cost, np.ndarray) else chosen_child_cost\n",
    "                            add_explanation(explanations, key='V', \n",
    "                                            node_name=chosen_child_name, \n",
    "                                            value=[chosen_child_cost_formatted, '>',child_name, child_cost_formatted])\n",
    "                            continue\n",
    "                        \n",
    "\n",
    "                        \"\"\"\n",
    "                        (e) A failed condition of a choice (\"F\"). Requested format:\n",
    "                            ['F', name of an alternative of an OR node that was NOT chosen because\n",
    "                            (some of) its pre-conditions were not satisfied,\n",
    "                            list of preconditions of the alternative that were NOT\n",
    "                            satisfied and made the choice not possible]\n",
    "                            Example: ['F', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "                        \"\"\"                        \n",
    "                        add_explanation(explanations, key='F', node_name=child_name, value=[unsatisfied_preconditions])\n",
    "                        continue\n",
    "            \n",
    "            \"\"\" (g) A goal (\"D\"). Requested format:\n",
    "                ['D', name of the goal]\n",
    "                Example: ['D', 'getKitchenCoffee']\n",
    "            \"\"\"\n",
    "            if current_node_type in ['SEQ', 'AND', 'OR'] and ancestor_names and len(ancestor_names) > 0 and current_node_name in ancestor_names:\n",
    "                add_explanation(explanations, key='D', value=[current_node_name])\n",
    "\n",
    "        # Check if the current node is the action to explain\n",
    "        if current_node_name == action_to_explain:\n",
    "            \"\"\"\n",
    "            (f) A link (“L\"). Requested format:\n",
    "                ['L', name of the node, '->', name of the linked node]\n",
    "                Example: ['L', 'payShop', '->', 'getCoffeeShop']\n",
    "                Note: a node a links to another node b if a's attribute \"link\" contains the\n",
    "                name of b. Furthermore, if the linked node b also has a link to another node c,\n",
    "                then the explanation should also include such a link (and all the links forming\n",
    "                a chain starting from a) to the explanation, i.e., for each link in the chain an\n",
    "                explanation in the requested format above should included in the list.\n",
    "            \"\"\"\n",
    "            add_linked_node_explanations(explanations, node, root)\n",
    "            # Stop the traversal if the action to explain is reached\n",
    "            break\n",
    "\n",
    "    \n",
    "\n",
    "    \"\"\" (h) The user preference (\"U\"). Requested format:\n",
    "        ['U' the pair given in input as user preference]\n",
    "        Example: ['U', [['quality', 'price', 'time'], [1, 2, 0]]]\n",
    "    \"\"\"\n",
    "    if preferences and len(preferences) == 2:\n",
    "        add_explanation(explanations, key='U', value=[preferences])\n",
    "\n",
    "\n",
    "    return explanations, chosen_trace\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "\"\"\"\n",
    "\n",
    "def handle_condition_explanation(action, formal_explention):\n",
    "    conditions = ', '.join(formal_explention[2])\n",
    "    return f\"The agent was able to perform the action '{action}' as all its preconditions ({conditions}) were successfully met.\"\n",
    "\n",
    "def handle_value_comparison_explanation(action1, values1, operator, action2, values2, preferences_labels, preferences_values, preference_labels_formatted):\n",
    "    value1_formatted = ', '.join([f\"{label}: {value}\" for label, value in zip(preferences_labels, values1)])\n",
    "    value2_formatted = ', '.join([f\"{label}: {value}\" for label, value in zip(preferences_labels, values2)])\n",
    "    \n",
    "    if values1 == values2:\n",
    "        return f\"Both actions have the same values for all factors ({value1_formatted}), so the agent randomly chose '{action1}' over '{action2}.\"\n",
    "    \n",
    "    explanation = f\"The agent chose '{action1}' over '{action2}' based on the user's preferences to prioritize {preference_labels_formatted}\"\n",
    "\n",
    "    # Compare the values succinctly\n",
    "    explanation += f\" and given that '{action1}' has these values: \" + value1_formatted\n",
    "    explanation += f\", while '{action2}' has: \" + value2_formatted\n",
    "\n",
    "    # Find the decisive factor\n",
    "    for index in preferences_values:\n",
    "        preference_label = preferences_labels[index]\n",
    "        value1 = values1[index]\n",
    "        value2 = values2[index]\n",
    "\n",
    "        if value1 != value2:\n",
    "            explanation += f\". The decisive factor was the {preference_label}, as '{action2}' had a higher value of {value2} compared to '{action1}' with {value1}. Lower values are more desirable, so '{action1}' was chosen.\"\n",
    "            break\n",
    "\n",
    "    # If all values are equal\n",
    "    if not any(value1 != value2 for value1, value2 in zip(values1, values2)):\n",
    "        explanation += f\". Since all factors were equally matched, the agent randomly chose the first action ({action1}).\"\n",
    "\n",
    "    return explanation\n",
    "\n",
    "def handle_norm_violation_explanation(action, formal_explention):\n",
    "    norm = formal_explention[2]\n",
    "    norm_type = norm[0]\n",
    "    norm_action = norm[2:-1]\n",
    "    \n",
    "    if norm_type == \"P\":  # Prohibition Norm\n",
    "        if norm_action == action:\n",
    "            return f\"The action '{action}' is not allowed because it violates the prohibition norm, which states that this action cannot be executed.\"\n",
    "        \n",
    "        return f\"The action '{action}' is not allowed because it leads to the execution of a prohibited action. The prohibition norm specifies that the following action must not be performed: {norm_action}.\"\n",
    "    \n",
    "    elif norm_type == \"O\":  # Obligation Norm\n",
    "        return f\"The action '{action}' is not allowed because it violates the obligation norm, which specifies that only the following action(s) are permitted: {norm_action}.\"\n",
    "\n",
    "def handle_precondition_explanation(action, formal_explention):\n",
    "    preconditions = formal_explention[2]\n",
    "    if len(preconditions) > 1:\n",
    "        preconditions_formatted = ', '.join(preconditions[:-1]) + ', and ' + preconditions[-1]\n",
    "        return f\"The agent could not perform '{action}' because the obligatory preconditions: {preconditions_formatted} were not met.\"\n",
    "    else:\n",
    "        preconditions_formatted = preconditions[0]\n",
    "        return f\"The agent could not perform '{action}' because the obligatory precondition: {preconditions_formatted} was not met.\"\n",
    "\n",
    "def handle_decision_explanation(action):\n",
    "    return f\"The agent chose to perform '{action}' as it is a necessary step to achieve the goal action.\"\n",
    "\n",
    "def handle_link_explanation(action, formal_explention):\n",
    "    linked_action = formal_explention[3]\n",
    "    return f\"The action '{action}' is linked to the action '{linked_action}', and as such, it was executed as a necessary step to achieve the goal action.\"\n",
    "\n",
    "def handle_utility_function_explanation(preferences):\n",
    "    preferences_labels = preferences[0]\n",
    "    preferences_values = preferences[1]\n",
    "    # Sort preferences_labels according to preferences_values\n",
    "    preference_labels_sorted = [preferences_labels[i] for i in preferences_values]\n",
    "    preference_labels_formatted = format_list_to_string(preference_labels_sorted)\n",
    "    return f\"The agent's preferences, in descending order of importance, are: {preference_labels_formatted}.\"\n",
    "\n",
    "def handle_failure_explanation(action, formal_explention):\n",
    "    \"\"\"\n",
    "    (e) A failed condition of a choice (\"F\"). Requested format:\n",
    "        ['F', name of an alternative of an OR node that was NOT chosen because\n",
    "        (some of) its pre-conditions were not satisfied,\n",
    "        list of preconditions of the alternative that were NOT\n",
    "        satisfied and made the choice not possible]\n",
    "        Example: ['F', 'getKitchenCoffee', ['staffCardAvailable']]\n",
    "    \"\"\"     \n",
    "    # action = formal_explention[1]\n",
    "    preconditions = formal_explention[2]\n",
    "    preconditions_labels_formatted = format_list_to_string(preconditions)\n",
    "    \n",
    "    return f\"The agent cound not executed '{action}' because of the preconditions for it, which are {preconditions_labels_formatted}, were not met.\"\n",
    "\n",
    "def generate_natural_explentions(formal_explention, preferences):\n",
    "    \"\"\"\n",
    "    Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "    :param formal_explention: a single formal explentions (output of part1-4)\n",
    "    :param preferences: user preferences\n",
    "    :return: natural language explention\n",
    "    \"\"\"\n",
    "    explanation_type = formal_explention[0]\n",
    "    action = formal_explention[1]\n",
    "    preferences_labels = preferences[0]\n",
    "    preferences_values = preferences[1]\n",
    "    # Sort preferences_labels according to preferences_values\n",
    "    preference_labels_sorted = [preferences_labels[i] for i in preferences_values]\n",
    "    preference_labels_formatted = format_list_to_string(preference_labels_sorted)\n",
    "\n",
    "    if explanation_type == 'C':  # Condition\n",
    "        return handle_condition_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'V':  # Value Comparison\n",
    "        action1, values1, operator, action2, values2 = formal_explention[1:]\n",
    "        return handle_value_comparison_explanation(action1, values1, operator, action2, values2, preferences_labels, preferences_values, preference_labels_formatted)\n",
    "    elif explanation_type == 'N':  # Norm Violation\n",
    "        return handle_norm_violation_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'P':  # Precondition\n",
    "        return handle_precondition_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'D':  # Decision\n",
    "        return handle_decision_explanation(action)\n",
    "    elif explanation_type == 'L':  # Link\n",
    "        return handle_link_explanation(action, formal_explention)\n",
    "    elif explanation_type == 'U':  # Utility Function\n",
    "        return handle_utility_function_explanation(preferences)\n",
    "    elif explanation_type == 'F':\n",
    "        return handle_failure_explanation(action, formal_explention)\n",
    "    \n",
    "    return \"Unknown explanation type.\"\n",
    "\n",
    "def format_list_to_string(lst):\n",
    "    \"\"\"\n",
    "    Format a list of strings into a single string with commas and 'and' before the last element.\n",
    "    :param lst: The list of strings to format.\n",
    "    :return: The formatted string.\n",
    "    \"\"\"\n",
    "\n",
    "    if len(lst) > 1:\n",
    "        return ', '.join(lst[:-1]) + ', and ' + lst[-1]\n",
    "    return lst[0]\n",
    "\n",
    "def generate_restriction_description(norm, goal, beliefs, preferences, action_to_explain):\n",
    "    \"\"\"\n",
    "    Generate a natural language description of the restrictions placed on the agent.\n",
    "    \n",
    "    Parameters:\n",
    "    norm (dict): The norm restricting or obligating actions.\n",
    "    goal (list): The desired outcome, represented as a set of beliefs that must be true by the end of execution.\n",
    "    beliefs (list): The agent's initial knowledge.\n",
    "    preferences (list): A pair describing the end-user's priority order.\n",
    "    action_to_explain (string): The action being analyzed.\n",
    "    \n",
    "    :return: A natural language description of the restrictions.\n",
    "    \"\"\"\n",
    "\n",
    "    restrictions = []\n",
    "\n",
    "    # Describe norm\n",
    "    if norm:\n",
    "        norm_type = norm.get(\"type\", \"Unknown\")\n",
    "        norm_actions = norm.get(\"actions\", [])\n",
    "\n",
    "        if norm_actions:\n",
    "            norm_action_str = format_list_to_string(norm_actions)\n",
    "            if norm_type == \"P\":\n",
    "                restrictions.append(f\"Restricted actions: {norm_action_str}.\")\n",
    "            elif norm_type == \"O\":\n",
    "                restrictions.append(f\"Required actions: {norm_action_str}.\")\n",
    "\n",
    "    # Describe initial beliefs\n",
    "    if beliefs:\n",
    "        restrictions.append(f\"Starting beliefs: {format_list_to_string(beliefs)}.\")\n",
    "\n",
    "    # Describe goal\n",
    "    if goal:\n",
    "        restrictions.append(f\"Goal: {format_list_to_string(goal)}.\")\n",
    "\n",
    "    # Describe preferences\n",
    "    preferences_description = handle_utility_function_explanation(preferences)\n",
    "    restrictions.append(preferences_description)\n",
    "\n",
    "    # Combine everything into a natural flow\n",
    "    restriction_sentence = \" \".join(restrictions)\n",
    "    return f\"To explain the action '{action_to_explain}', consider the following context: {restriction_sentence}\"\n",
    "\n",
    "\n",
    "def generate_naive_baseline(formal_explentions, chosen_trace, norm, goal, beliefs, preferences, action_to_explain):\n",
    "    \"\"\"\n",
    "    Generate naive baseline approach of if-else rules to generate natural language explanations\n",
    "    \n",
    "    Parameters:\n",
    "    formal_explentions (list): list of formal explentions (output of part1-4)\n",
    "    chosen_trace (list): chosen trace\n",
    "    norm (dict): The norm\n",
    "    goal (list): The goal of the agent: a set of beliefs (strings) of the agent that must be true at the end of the execution of the trace.\n",
    "    beliefs (list): A set of strings representing the initial beliefs of the agents.\n",
    "    preferences (list): A pair describing the preference of the end-user.\n",
    "    action_to_explain (string): The name of the action to explain.\n",
    "\n",
    "    :return: list of natural language explentions\n",
    "    \"\"\"\n",
    "    natural_explentions = []\n",
    "    # Format the chosen trace for display\n",
    "    chosen_trace_formatted = \"\"\n",
    "    if chosen_trace is not None and len(chosen_trace) > 0:\n",
    "       chosen_trace_formatted = format_list_to_string(chosen_trace)\n",
    "\n",
    "    restriction_description = generate_restriction_description(norm, goal, beliefs, preferences, action_to_explain)\n",
    "    natural_explentions.append(restriction_description)\n",
    "\n",
    "    if formal_explentions is None or len(formal_explentions) == 0:\n",
    "        if chosen_trace:\n",
    "            natural_explentions.append(\n",
    "                f\"The action '{action_to_explain}' was not executed in the chosen trace ({chosen_trace_formatted}).\"\n",
    "            )\n",
    "\n",
    "        if norm and norm.get(\"type\") == \"P\" and action_to_explain in norm.get(\"actions\", []):\n",
    "            natural_explentions.append(\"This action is restricted by the norm and therefore could not be executed.\")\n",
    "\n",
    "        return natural_explentions\n",
    "\n",
    "    # Generate natural language explanations for each formal explanation\n",
    "    for explention in formal_explentions:\n",
    "        natural_explentions.append(generate_natural_explentions(explention, preferences))\n",
    "\n",
    "    return natural_explentions\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changed pipeline a bit, added preorder_traversal list to follow the order in which the agent decides what to do;\n",
    "### function generate_comprehensive_explanation generates response from mistral https://ollama.com/library/mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "\n",
    "from anytree import PreOrderIter\n",
    "\n",
    "def preorder_traversal(root):\n",
    "    \"\"\"\n",
    "    Performs a preorder traversal of a tree and returns a list of node names.\n",
    "    \n",
    "    :param root: The root node of the tree.\n",
    "    :return: A list of node names in preorder traversal order.\n",
    "    \"\"\"\n",
    "    preorder_traversal_nodes = []\n",
    "    \n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        print(current_node_name)\n",
    "        preorder_traversal_nodes.append(current_node_name)\n",
    "    \n",
    "    return preorder_traversal_nodes\n",
    "\n",
    "\n",
    "def generate_comprehensive_explanation(naive_explanation, formal_explanations, tree_traversal_order, \n",
    "                                     norm, beliefs, goal, preferences, action_to_explain, chosen_trace=None):\n",
    "    \n",
    "    # Format key context elements\n",
    "    norm_str = f\"{norm['type']}({', '.join(norm['actions'])})\" if norm and 'type' in norm and 'actions' in norm else \"None\"\n",
    "    beliefs_str = \", \".join(beliefs) if beliefs else \"None\"\n",
    "    goal_str = \", \".join(goal) if goal else \"None\"\n",
    "    \n",
    "    pref_description = \"None\"\n",
    "    if preferences and len(preferences) == 2 and len(preferences[0]) > 0:\n",
    "        pref_items = [f\"{preferences[0][i]}\" for i in range(len(preferences[0]))]\n",
    "        pref_values = preferences[1] if len(preferences) > 1 and len(preferences[1]) > 0 else []\n",
    "        pref_description = \", \".join(pref_items)\n",
    "    \n",
    "    chosen_trace_str = \", \".join(chosen_trace) if chosen_trace else \"None\"\n",
    "    \n",
    "    # Construct comprehensive prompt\n",
    "    prompt = f\"\"\"\n",
    "    You are an advanced AI tasked with explaining an agent's decision-making process in natural language. \n",
    "    Generate a cohesive explanation that follows the agent's reasoning process exactly as it traversed its goal tree.\n",
    "    \n",
    "    CONTEXT INFORMATION:\n",
    "    - Action being explained: {action_to_explain}\n",
    "    - Norm (restriction): {norm_str}\n",
    "    - Initial beliefs: {beliefs_str}\n",
    "    - Goal: {goal_str}\n",
    "    - User preferences: {pref_description}\n",
    "    - Chosen execution trace: {chosen_trace_str}\n",
    "    \n",
    "    TRAVERSAL ORDER (how the agent explored options):\n",
    "    {tree_traversal_order}\n",
    "    \n",
    "    FORMAL EXPLANATIONS (detailed reasoning for each decision):\n",
    "    {formal_explanations}\n",
    "    \n",
    "    EXISTING EXPLANATION (needs reorganization):\n",
    "    {naive_explanation}\n",
    "    \n",
    "    YOUR TASK:\n",
    "    1. Create a clear, flowing explanation that follows the pre-order traversal order exactly\n",
    "    2. Start with a brief context paragraph (goal, constraints, preferences)\n",
    "    3. Explain each decision point in the traversal order, showing how:\n",
    "       - The agent started with the main goal\n",
    "       - How it evaluated each option systematically\n",
    "       - Why certain paths were chosen and others rejected\n",
    "       - How preconditions, norms, and preferences influenced decisions\n",
    "    4. For each formal explanation code, translate it to natural language:\n",
    "       - For P codes: Explain which preconditions enabled an action\n",
    "       - For C codes: Explain which conditions allowed a choice\n",
    "       - For F codes: Explain why certain options were impossible\n",
    "       - For N codes: Explain which norms prevented certain actions \n",
    "       - For V codes: Explain why one alternative was preferred over another\n",
    "       - For L codes: Explain how actions are connected/dependent\n",
    "       - For D codes: Explain goal-directed actions\n",
    "       - For U codes: Explain user preferences' influence\n",
    "    \n",
    "    IMPORTANT GUIDELINES:\n",
    "    - Follow the exact traversal order in your explanation\n",
    "    - Use simple, conversational language (avoid technical terms) \n",
    "    - Create a narrative that shows causality (why each decision led to the next)\n",
    "    - Mention the specifically requested action ({action_to_explain}) and explain its role\n",
    "    - Keep the explanation concise yet complete\n",
    "    - Format as a flowing paragraph, not bullet points\n",
    "    \n",
    "    Create a natural language explanation that a non-technical user would understand:\n",
    "    \"\"\"\n",
    "    \n",
    "    # Send the conversation to the LLM\n",
    "    messages = [\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': prompt\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    response = ollama.chat(model='mistral', messages=messages)\n",
    "    \n",
    "    return response['message']['content']\n",
    "\n",
    "\n",
    "def preorder_traversal(root):\n",
    "    \"\"\"\n",
    "    Performs a preorder traversal of a tree and returns a list of node names.\n",
    "    \n",
    "    :param root: The root node of the tree.\n",
    "    :return: A list of node names in preorder traversal order.\n",
    "    \"\"\"\n",
    "    preorder_traversal_nodes = []\n",
    "    \n",
    "    for node in PreOrderIter(root):\n",
    "        current_node_name = node.name\n",
    "        print(current_node_name)\n",
    "        preorder_traversal_nodes.append(current_node_name)\n",
    "    \n",
    "    return preorder_traversal_nodes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Integrated here llm explanations and save them into explanations/mistral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_explanations_for_inputs(test_cases):\n",
    "    \"\"\"\n",
    "    Generate explanations for the inputs test cases\n",
    "    :param test_cases: dictionary containing the test cases\n",
    "    :return: dictionary containing the explanations for each test case\n",
    "    \"\"\"\n",
    "    \n",
    "    # in .ipynb current directory is extracted like this\n",
    "    current_dir = os.getcwd()\n",
    "\n",
    "    # current_dir = os.path.dirname(__file__)\n",
    "\n",
    "    baseline_explanations_dir = os.path.join(current_dir, \"explanations\", \"baseline\")\n",
    "    os.makedirs(baseline_explanations_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    llm_explanations_dir = os.path.join(current_dir, \"explanations\", \"mistral\")\n",
    "    \n",
    "    baseline_explanations = {}\n",
    "    llm_explanations = {}\n",
    "    for index, row in test_cases.iterrows():\n",
    "        # Read the JSON file into a dictionary\n",
    "        with open(f'{current_dir}/{row[\"name_json_tree_file\"]}', 'r') as file:\n",
    "            json_tree = json.load(file)\n",
    "        # Generate formal explanations\n",
    "        formal_explentions, chosen_trace = generate_formal_explanations(json_tree=json_tree, norm=row[\"norm\"], beliefs=row[\"beliefs\"], goal=row[\"goal\"], preferences=row[\"preferences\"], action_to_explain=row[\"action_to_explain\"])\n",
    "        baseline_explanations[index] = generate_naive_baseline(formal_explentions=formal_explentions, chosen_trace=chosen_trace, norm=row[\"norm\"], beliefs=row[\"beliefs\"], goal=row[\"goal\"], preferences=row[\"preferences\"], action_to_explain=row[\"action_to_explain\"])\n",
    "\n",
    "\n",
    "\n",
    "        root, chosen_trace, valid_traces, valid_costs = make_decision(json_tree, norm=row[\"norm\"], goal=row[\"goal\"], beliefs=row[\"beliefs\"], preferences=row[\"preferences\"], output_dir='/')\n",
    "        tree_traversal_order = preorder_traversal(root=root)\n",
    "\n",
    "        llm_explanations[index] = generate_comprehensive_explanation(\n",
    "                        naive_explanation=baseline_explanations[index],\n",
    "                        formal_explanations=formal_explentions,\n",
    "                        tree_traversal_order=tree_traversal_order,\n",
    "                        norm=row[\"norm\"],\n",
    "                        beliefs=row[\"beliefs\"],\n",
    "                        goal=row[\"goal\"],\n",
    "                        preferences=row[\"preferences\"],\n",
    "                        action_to_explain=row[\"action_to_explain\"],\n",
    "                        chosen_trace=chosen_trace\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # Save each explanation to a separate text file\n",
    "        baseline_explanation_file = os.path.join(baseline_explanations_dir, f\"{index}.txt\")\n",
    "        with open(baseline_explanation_file, 'w') as f:\n",
    "            for explanation in baseline_explanations[index]:\n",
    "                f.write(explanation + '\\n')\n",
    "\n",
    "\n",
    "        os.makedirs(llm_explanations_dir, exist_ok=True)  \n",
    "\n",
    "        llm_explanation_file = os.path.join(llm_explanations_dir, f\"{index}.txt\")\n",
    "\n",
    "        print(f\"directory ---> {llm_explanation_file}\")\n",
    "        \n",
    "        # with open(llm_explanation_file, 'w') as f:\n",
    "        #     for explanation in llm_explanations[index]:\n",
    "        #         f.write(explanation + '\\n')\n",
    "\n",
    "        # Loop through the dictionary and write explanations for each test case\n",
    "        with open(llm_explanation_file, 'w') as f:\n",
    "            for explanation in llm_explanations[index]:\n",
    "                # Write the explanation for this test case\n",
    "                f.write(explanation)   # Add an extra newline for separation\n",
    "\n",
    "        \n",
    "    \n",
    "    return baseline_explanations, llm_explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"payShop\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [1, 2, 0]],\n",
    "        \"action_to_explain\": \"payShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"getCoffeeKitchen\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {},\n",
    "        \"beliefs\": [\"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"getCoffeeShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"gotoAnnOffice\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\", \"AnnInOffice\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [0, 1, 2]],\n",
    "        \"action_to_explain\": \"payShop\"\n",
    "    },\n",
    "    {\n",
    "        \"name_json_tree_file\": \"coffee.json\",\n",
    "        \"norm\": {\"type\": \"P\", \"actions\": [\"payShop\"]},\n",
    "        \"beliefs\": [\"staffCardAvailable\", \"ownCard\", \"colleagueAvailable\", \"haveMoney\"],\n",
    "        \"goal\": [\"haveCoffee\"],\n",
    "        \"preferences\": [[\"quality\", \"price\", \"time\"], [1, 2, 0]],\n",
    "        \"action_to_explain\": \"gotoKitchen\"\n",
    "    }\n",
    "]\n",
    "\n",
    "df_test_cases = pd.DataFrame(test_cases, index=[f\"test_case_{i+1}\" for i in range(len(test_cases))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen trace: ['getCoffee', 'getKitchenCoffee', 'getStaffCard', 'getOwnCard', 'gotoKitchen', 'getCoffeeKitchen']\n",
      "Action to explain: payShop not in trace\n",
      "getCoffee\n",
      "getKitchenCoffee\n",
      "getStaffCard\n",
      "getOwnCard\n",
      "getOthersCard\n",
      "gotoKitchen\n",
      "getCoffeeKitchen\n",
      "getAnnOfficeCoffee\n",
      "gotoAnnOffice\n",
      "getPod\n",
      "getCoffeeAnnOffice\n",
      "getShopCoffee\n",
      "gotoShop\n",
      "payShop\n",
      "getCoffeeShop\n"
     ]
    },
    {
     "ename": "ConnectionError",
     "evalue": "Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m baseline_explanations, llm_explanations \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_explanations_for_inputs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_test_cases\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[5], line 34\u001b[0m, in \u001b[0;36mgenerate_explanations_for_inputs\u001b[0;34m(test_cases)\u001b[0m\n\u001b[1;32m     31\u001b[0m root, chosen_trace, valid_traces, valid_costs \u001b[38;5;241m=\u001b[39m make_decision(json_tree, norm\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnorm\u001b[39m\u001b[38;5;124m\"\u001b[39m], goal\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgoal\u001b[39m\u001b[38;5;124m\"\u001b[39m], beliefs\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbeliefs\u001b[39m\u001b[38;5;124m\"\u001b[39m], preferences\u001b[38;5;241m=\u001b[39mrow[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpreferences\u001b[39m\u001b[38;5;124m\"\u001b[39m], output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     32\u001b[0m tree_traversal_order \u001b[38;5;241m=\u001b[39m preorder_traversal(root\u001b[38;5;241m=\u001b[39mroot)\n\u001b[0;32m---> 34\u001b[0m llm_explanations[index] \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_comprehensive_explanation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnaive_explanation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbaseline_explanations\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m                \u001b[49m\u001b[43mformal_explanations\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mformal_explentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     37\u001b[0m \u001b[43m                \u001b[49m\u001b[43mtree_traversal_order\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtree_traversal_order\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[43m                \u001b[49m\u001b[43mnorm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnorm\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[43m                \u001b[49m\u001b[43mbeliefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbeliefs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m                \u001b[49m\u001b[43mgoal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgoal\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m                \u001b[49m\u001b[43mpreferences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpreferences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m                \u001b[49m\u001b[43maction_to_explain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_to_explain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                \u001b[49m\u001b[43mchosen_trace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchosen_trace\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# Save each explanation to a separate text file\u001b[39;00m\n\u001b[1;32m     48\u001b[0m baseline_explanation_file \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(baseline_explanations_dir, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mindex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[4], line 98\u001b[0m, in \u001b[0;36mgenerate_comprehensive_explanation\u001b[0;34m(naive_explanation, formal_explanations, tree_traversal_order, norm, beliefs, goal, preferences, action_to_explain, chosen_trace)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Send the conversation to the LLM\u001b[39;00m\n\u001b[1;32m     91\u001b[0m messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     92\u001b[0m     {\n\u001b[1;32m     93\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrole\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     94\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt\n\u001b[1;32m     95\u001b[0m     }\n\u001b[1;32m     96\u001b[0m ]\n\u001b[0;32m---> 98\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmistral\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xai/lib/python3.10/site-packages/ollama/_client.py:333\u001b[0m, in \u001b[0;36mClient.chat\u001b[0;34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[0m\n\u001b[1;32m    289\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mchat\u001b[39m(\n\u001b[1;32m    290\u001b[0m   \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    291\u001b[0m   model: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    298\u001b[0m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    299\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[1;32m    300\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;124;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[1;32m    302\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;124;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[1;32m    332\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 333\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    334\u001b[0m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    335\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPOST\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/chat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xai/lib/python3.10/site-packages/ollama/_client.py:178\u001b[0m, in \u001b[0;36mClient._request\u001b[0;34m(self, cls, stream, *args, **kwargs)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpart)\n\u001b[1;32m    176\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[0;32m--> 178\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson())\n",
      "File \u001b[0;32m/opt/anaconda3/envs/xai/lib/python3.10/site-packages/ollama/_client.py:124\u001b[0m, in \u001b[0;36mClient._request_raw\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mtext, e\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mstatus_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mConnectError:\n\u001b[0;32m--> 124\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mConnectionError\u001b[0m: Failed to connect to Ollama. Please check that Ollama is downloaded, running and accessible. https://ollama.com/download"
     ]
    }
   ],
   "source": [
    "baseline_explanations, llm_explanations = generate_explanations_for_inputs(df_test_cases)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
